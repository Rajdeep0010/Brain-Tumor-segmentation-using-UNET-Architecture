{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* ### ***Streamlite deployment***\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ECmSvE-wtop",
        "outputId": "98c4e130-58ed-402e-8544-1adb9c67a483"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB4N46rcfL16"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"358J96RoaekkhqIFd55Z1OihaFr_6rczzfHtYKSxHEWFs4D9F\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f560G0VWhpW5",
        "outputId": "74227060-0ce5-45ee-ab25-5a83fbd2c452"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.models import load_model\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "#Prediction function\n",
        "def predict_and_explain(model, image_array, layer_name, img_size=128):\n",
        "  #load and preprocess the image\n",
        "    img_resized = cv2.resize(image_array, (img_size, img_size))\n",
        "    img_norm = img_resized / 255.0\n",
        "    input_img = np.expand_dims(img_norm, axis=0)\n",
        "\n",
        "    #prediction of the mask\n",
        "    pred_mask = model.predict(input_img)\n",
        "    pred_mask = (pred_mask > 0.5).astype(np.uint8)\n",
        "    pred_mask_vis = np.squeeze(pred_mask)\n",
        "\n",
        "    #Integrating GRADE cam\n",
        "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(input_img)\n",
        "        loss = tf.reduce_mean(predictions)\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    cam = np.zeros(conv_outputs.shape[:2], dtype=np.float32)\n",
        "    for i, w in enumerate(pooled_grads):\n",
        "        cam += w * conv_outputs[:, :, i]\n",
        "    cam = np.maximum(cam, 0)\n",
        "    cam = cam / np.max(cam)\n",
        "\n",
        "    #applying heatmap overlay\n",
        "    cam_resized = cv2.resize(cam, (img_size, img_size))\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "    overlay = np.uint8(0.6 * heatmap + 0.4 * (img_resized * 255))\n",
        "\n",
        "    return img_resized, pred_mask_vis, overlay\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqNRarO7vjkb",
        "outputId": "8c57b250-89ab-4ddb-9027-488434f1a921"
      },
      "outputs": [],
      "source": [
        "#Streamlite UI\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Streamlit UI\n",
        "st.set_page_config(page_title=\"MRI Segmentation + GradCAM\", layout=\"wide\")\n",
        "\n",
        "st.set_page_config(page_title=\"MRI Segmentation + GradCAM\", layout=\"wide\")\n",
        "\n",
        "# Custom CSS\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .main {\n",
        "        background-color: #f8fafc;\n",
        "        font-family: 'Segoe UI', sans-serif;\n",
        "    }\n",
        "    .stButton>button {\n",
        "        background-color: #2b6cb0;\n",
        "        color: white;\n",
        "        font-weight: bold;\n",
        "        border-radius: 10px;\n",
        "        height: 3em;\n",
        "        width: 100%;\n",
        "        border: none;\n",
        "    }\n",
        "    .stButton>button:hover {\n",
        "        background-color: #1e4e8c;\n",
        "        color: white;\n",
        "    }\n",
        "    img {\n",
        "        border-radius: 10px;\n",
        "    }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Header Section\n",
        "st.markdown(\"## Brain MRI Segmentation with Explainable AI (Grad-CAM)\")\n",
        "st.markdown(\"\"\"\n",
        "**This model used to segment out the tumour region from the MRI Image**\n",
        "and highlights the **most influential regions** using **Grad-CAM heatmaps**\n",
        "\"\"\")\n",
        "\n",
        "st.divider()\n",
        "\n",
        "# Image upload\n",
        "uploaded = st.file_uploader(\"Upload an MRI Image\", type=[\"png\", \"jpg\", \"jpeg\",\"tif\"])\n",
        "\n",
        "if uploaded:\n",
        "    file_bytes = np.asarray(bytearray(uploaded.read()), dtype=np.uint8)\n",
        "    image = cv2.imdecode(file_bytes, 1)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    st.image(image, caption=\"Uploaded MRI (Preview)\", width=300)\n",
        "\n",
        "    st.markdown(\"#### Ready to analyze this image?\")\n",
        "    if st.button(\"Run\"):\n",
        "        with st.spinner(\"Running model... generating segmentation and Grad-CAM...\"):\n",
        "            model = load_model(\"/content/drive/MyDrive/project_datasets/segmented_model(50epoch).h5\", compile=False)\n",
        "            last_conv_layer = \"conv2d_10\"\n",
        "            input_img, mask, overlay = predict_and_explain(model, image, last_conv_layer)\n",
        "        st.success(\"Prediction complete!\")\n",
        "\n",
        "        st.divider()\n",
        "\n",
        "        # Display results\n",
        "        st.markdown(\"### Model Results\")\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.image(input_img, caption=\"Input MRI\", use_container_width=True)\n",
        "        with col2:\n",
        "            st.image(mask * 255, caption=\"Predicted Mask\", use_container_width=True)\n",
        "        with col3:\n",
        "            st.image(overlay, caption=\"Grad-CAM Explanation\", use_container_width=True)\n",
        "\n",
        "        st.divider()\n",
        "\n",
        "        # Download buttons\n",
        "        mask_img = Image.fromarray((mask * 255).astype(np.uint8))\n",
        "        overlay_img = Image.fromarray(overlay)\n",
        "\n",
        "        buf1, buf2 = BytesIO(), BytesIO()\n",
        "        mask_img.save(buf1, format=\"PNG\")\n",
        "        overlay_img.save(buf2, format=\"PNG\")\n",
        "\n",
        "        st.download_button(\"Download Predicted Mask\", data=buf1.getvalue(),\n",
        "                           file_name=\"predicted_mask.png\", mime=\"image/png\")\n",
        "\n",
        "        st.download_button(\"Download Grad-CAM Heatmap\", data=buf2.getvalue(),\n",
        "                           file_name=\"gradcam_heatmap.png\", mime=\"image/png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RK4_wkDVLOQ"
      },
      "outputs": [],
      "source": [
        "!nohup streamlit run app.py --server.port 8501 &>/dev/null&"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCLqn4ATbgiK",
        "outputId": "3fe1f35f-2f2e-4053-d3d7-aad40c99c18c"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(addr=\"8501\")\n",
        "print(\"Streamlit App Live at:\")\n",
        "print(public_url.public_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UnFkT0YwK2h"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "brain_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
